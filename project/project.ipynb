{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import absolute\n",
    "import matplotlib.pyplot as plt\n",
    "import ta\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Marketcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>ADA</td>\n",
       "      <td>2017-10-02 23:59:59</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>57641300.0</td>\n",
       "      <td>6.288991e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>ADA</td>\n",
       "      <td>2017-10-03 23:59:59</td>\n",
       "      <td>0.027425</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>16997800.0</td>\n",
       "      <td>5.396927e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>ADA</td>\n",
       "      <td>2017-10-04 23:59:59</td>\n",
       "      <td>0.022806</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.020864</td>\n",
       "      <td>0.021931</td>\n",
       "      <td>9000050.0</td>\n",
       "      <td>5.686195e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>ADA</td>\n",
       "      <td>2017-10-05 23:59:59</td>\n",
       "      <td>0.022154</td>\n",
       "      <td>0.020859</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>5562510.0</td>\n",
       "      <td>5.571390e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cardano</td>\n",
       "      <td>ADA</td>\n",
       "      <td>2017-10-06 23:59:59</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>0.018539</td>\n",
       "      <td>7780710.0</td>\n",
       "      <td>4.806646e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SNo     Name Symbol                 Date      High       Low      Open  \\\n",
       "0    1  Cardano    ADA  2017-10-02 23:59:59  0.030088  0.019969  0.024607   \n",
       "1    2  Cardano    ADA  2017-10-03 23:59:59  0.027425  0.020690  0.025757   \n",
       "2    3  Cardano    ADA  2017-10-04 23:59:59  0.022806  0.020864  0.020864   \n",
       "3    4  Cardano    ADA  2017-10-05 23:59:59  0.022154  0.020859  0.021951   \n",
       "4    5  Cardano    ADA  2017-10-06 23:59:59  0.021542  0.018360  0.021359   \n",
       "\n",
       "      Close      Volume     Marketcap  \n",
       "0  0.025932  57641300.0  6.288991e+08  \n",
       "1  0.020816  16997800.0  5.396927e+08  \n",
       "2  0.021931   9000050.0  5.686195e+08  \n",
       "3  0.021489   5562510.0  5.571390e+08  \n",
       "4  0.018539   7780710.0  4.806646e+08  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data \n",
    "\n",
    "Cardano = pd.read_csv(\"/Users/nicolaspaganel/Desktop/GitHub/ML_Finance/Crypto df/coin_Cardano.csv\") \n",
    "\n",
    "# let's have a look at the data\n",
    "plt.plot(Cardano[\"Close\"])\n",
    "plt.ylabel(\"Close price\")\n",
    "Crypto_name = Cardano[\"Name\"][0]\n",
    "plt.title(\"Price evolution of \" + Crypto_name)\n",
    "Cardano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ta/trend.py:768: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i] / self._trs[i])\n",
      "/opt/anaconda3/lib/python3.8/site-packages/ta/trend.py:772: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i] / self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "# Clean nan values\n",
    "\n",
    "Cardano = ta.utils.dropna(Cardano)\n",
    "\n",
    "# Add all technical analysis features filling nans values\n",
    "\n",
    "Cardano = ta.add_all_ta_features(Cardano, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)\n",
    "\n",
    "#print(Cardano.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of our indicators \n",
    "\n",
    "indicators = ['volume_adi', 'volume_obv', 'volume_cmf',\n",
    "       'volume_fi', 'volume_mfi', 'volume_em', 'volume_sma_em', 'volume_vpt',\n",
    "       'volume_nvi', 'volume_vwap', 'volatility_atr', 'volatility_bbm',\n",
    "       'volatility_bbh', 'volatility_bbl', 'volatility_bbw', 'volatility_bbp',\n",
    "       'volatility_bbhi', 'volatility_bbli', 'volatility_kcc',\n",
    "       'volatility_kch', 'volatility_kcl', 'volatility_kcw', 'volatility_kcp',\n",
    "       'volatility_kchi', 'volatility_kcli', 'volatility_dcl',\n",
    "       'volatility_dch', 'volatility_dcm', 'volatility_dcw', 'volatility_dcp',\n",
    "       'volatility_ui', 'trend_macd', 'trend_macd_signal', 'trend_macd_diff',\n",
    "       'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow',\n",
    "       'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos',\n",
    "       'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix',\n",
    "       'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
    "       'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
    "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
    "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
    "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
    "       'trend_psar_down', 'trend_psar_up_indicator',\n",
    "       'trend_psar_down_indicator', 'trend_stc', 'momentum_rsi',\n",
    "       'momentum_stoch_rsi', 'momentum_stoch_rsi_k', 'momentum_stoch_rsi_d',\n",
    "       'momentum_tsi', 'momentum_uo', 'momentum_stoch',\n",
    "       'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_kama',\n",
    "       'momentum_roc', 'momentum_ppo', 'momentum_ppo_signal',\n",
    "       'momentum_ppo_hist', 'others_cr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'others_dr', 'others_dlr', between 'momentum_ppo_hist' and 'others_cr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>volume_mfi</th>\n",
       "      <th>volume_em</th>\n",
       "      <th>volume_sma_em</th>\n",
       "      <th>volume_vpt</th>\n",
       "      <th>volume_nvi</th>\n",
       "      <th>volume_vwap</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_stoch_signal</th>\n",
       "      <th>momentum_wr</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>momentum_roc</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.070702e+06</td>\n",
       "      <td>4.064350e+07</td>\n",
       "      <td>-0.081334</td>\n",
       "      <td>-8.696073e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-5.516302e+07</td>\n",
       "      <td>802.713311</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>...</td>\n",
       "      <td>33.646631</td>\n",
       "      <td>-91.634039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.934792</td>\n",
       "      <td>-1.186958</td>\n",
       "      <td>-4.747833</td>\n",
       "      <td>-19.728669</td>\n",
       "      <td>-0.197287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.178208e+06</td>\n",
       "      <td>4.964355e+07</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>-7.310329e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-2.871049e+06</td>\n",
       "      <td>845.737644</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>...</td>\n",
       "      <td>28.895217</td>\n",
       "      <td>-80.607609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.455387</td>\n",
       "      <td>-3.440644</td>\n",
       "      <td>-9.014743</td>\n",
       "      <td>-15.426236</td>\n",
       "      <td>0.053599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.330769e+06</td>\n",
       "      <td>4.408104e+07</td>\n",
       "      <td>-0.059761</td>\n",
       "      <td>-6.301183e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>3.700827e+05</td>\n",
       "      <td>828.662115</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>...</td>\n",
       "      <td>14.258188</td>\n",
       "      <td>-84.983787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.898524</td>\n",
       "      <td>-6.532220</td>\n",
       "      <td>-12.366304</td>\n",
       "      <td>-17.133788</td>\n",
       "      <td>-0.020190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.223418e+07</td>\n",
       "      <td>3.630033e+07</td>\n",
       "      <td>-0.126149</td>\n",
       "      <td>-5.728871e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-1.180310e+06</td>\n",
       "      <td>828.662115</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>...</td>\n",
       "      <td>11.979427</td>\n",
       "      <td>-98.470322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-24.170970</td>\n",
       "      <td>-10.059970</td>\n",
       "      <td>-14.111000</td>\n",
       "      <td>-28.508237</td>\n",
       "      <td>-0.137263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.295668e+06</td>\n",
       "      <td>4.371157e+07</td>\n",
       "      <td>-0.050728</td>\n",
       "      <td>-4.656170e+04</td>\n",
       "      <td>14.641568</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-1.078525e+05</td>\n",
       "      <td>936.017905</td>\n",
       "      <td>0.023620</td>\n",
       "      <td>...</td>\n",
       "      <td>14.393974</td>\n",
       "      <td>-73.363969</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>0.020903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.900125</td>\n",
       "      <td>-13.828001</td>\n",
       "      <td>-15.072124</td>\n",
       "      <td>-19.246254</td>\n",
       "      <td>0.129553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1.489636e+11</td>\n",
       "      <td>1.606680e+11</td>\n",
       "      <td>0.079485</td>\n",
       "      <td>7.715935e+06</td>\n",
       "      <td>40.803677</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>2.578090e+07</td>\n",
       "      <td>1.340988</td>\n",
       "      <td>1.287375</td>\n",
       "      <td>...</td>\n",
       "      <td>74.826267</td>\n",
       "      <td>-14.425005</td>\n",
       "      <td>-0.130026</td>\n",
       "      <td>1.413802</td>\n",
       "      <td>-2.434291</td>\n",
       "      <td>-14.631161</td>\n",
       "      <td>-12.570468</td>\n",
       "      <td>-2.060693</td>\n",
       "      <td>5277.170314</td>\n",
       "      <td>0.044014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1.492675e+11</td>\n",
       "      <td>1.626961e+11</td>\n",
       "      <td>0.048280</td>\n",
       "      <td>1.021755e+07</td>\n",
       "      <td>45.608411</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>1.131361e+08</td>\n",
       "      <td>1.352951</td>\n",
       "      <td>1.287734</td>\n",
       "      <td>...</td>\n",
       "      <td>80.572709</td>\n",
       "      <td>-11.705474</td>\n",
       "      <td>-0.111837</td>\n",
       "      <td>1.413342</td>\n",
       "      <td>19.478555</td>\n",
       "      <td>-15.794977</td>\n",
       "      <td>-13.215370</td>\n",
       "      <td>-2.579607</td>\n",
       "      <td>5325.137984</td>\n",
       "      <td>0.008921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1.499232e+11</td>\n",
       "      <td>1.645025e+11</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>2.200846e+07</td>\n",
       "      <td>50.762187</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8.402275e+07</td>\n",
       "      <td>1.402332</td>\n",
       "      <td>1.288290</td>\n",
       "      <td>...</td>\n",
       "      <td>88.876266</td>\n",
       "      <td>-7.240723</td>\n",
       "      <td>-0.092363</td>\n",
       "      <td>1.415273</td>\n",
       "      <td>26.440825</td>\n",
       "      <td>-17.309043</td>\n",
       "      <td>-14.034104</td>\n",
       "      <td>-3.274938</td>\n",
       "      <td>5523.151544</td>\n",
       "      <td>0.036499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1.492638e+11</td>\n",
       "      <td>1.627430e+11</td>\n",
       "      <td>-0.003602</td>\n",
       "      <td>5.470805e+06</td>\n",
       "      <td>53.162599</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.635093e+06</td>\n",
       "      <td>1.351087</td>\n",
       "      <td>1.296258</td>\n",
       "      <td>...</td>\n",
       "      <td>87.651515</td>\n",
       "      <td>-18.099257</td>\n",
       "      <td>-0.068013</td>\n",
       "      <td>1.414355</td>\n",
       "      <td>12.132075</td>\n",
       "      <td>-18.599922</td>\n",
       "      <td>-14.947268</td>\n",
       "      <td>-3.652654</td>\n",
       "      <td>5317.665228</td>\n",
       "      <td>-0.036543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>1.489370e+11</td>\n",
       "      <td>1.642207e+11</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>7.466188e+06</td>\n",
       "      <td>62.537262</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-5.045959e+07</td>\n",
       "      <td>1.363738</td>\n",
       "      <td>1.326553</td>\n",
       "      <td>...</td>\n",
       "      <td>84.947809</td>\n",
       "      <td>-19.816594</td>\n",
       "      <td>-0.041889</td>\n",
       "      <td>1.414740</td>\n",
       "      <td>4.569426</td>\n",
       "      <td>-20.480104</td>\n",
       "      <td>-16.053835</td>\n",
       "      <td>-4.426268</td>\n",
       "      <td>5368.392753</td>\n",
       "      <td>0.009363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1373 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        volume_adi    volume_obv  volume_cmf     volume_fi  volume_mfi  \\\n",
       "1    -6.070702e+06  4.064350e+07   -0.081334 -8.696073e+04    0.000000   \n",
       "2    -5.178208e+06  4.964355e+07   -0.061911 -7.310329e+04    0.000000   \n",
       "3    -5.330769e+06  4.408104e+07   -0.059761 -6.301183e+04    0.000000   \n",
       "4    -1.223418e+07  3.630033e+07   -0.126149 -5.728871e+04    0.000000   \n",
       "5    -5.295668e+06  4.371157e+07   -0.050728 -4.656170e+04   14.641568   \n",
       "...            ...           ...         ...           ...         ...   \n",
       "1369  1.489636e+11  1.606680e+11    0.079485  7.715935e+06   40.803677   \n",
       "1370  1.492675e+11  1.626961e+11    0.048280  1.021755e+07   45.608411   \n",
       "1371  1.499232e+11  1.645025e+11    0.034713  2.200846e+07   50.762187   \n",
       "1372  1.492638e+11  1.627430e+11   -0.003602  5.470805e+06   53.162599   \n",
       "1373  1.489370e+11  1.642207e+11    0.023519  7.466188e+06   62.537262   \n",
       "\n",
       "      volume_em  volume_sma_em    volume_vpt  volume_nvi  volume_vwap  ...  \\\n",
       "1     -0.000038      -0.000038 -5.516302e+07  802.713311     0.024794  ...   \n",
       "2     -0.000048      -0.000043 -2.871049e+06  845.737644     0.024479  ...   \n",
       "3     -0.000008      -0.000031  3.700827e+05  828.662115     0.024293  ...   \n",
       "4     -0.000064      -0.000039 -1.180310e+06  828.662115     0.023907  ...   \n",
       "5     -0.000028      -0.000037 -1.078525e+05  936.017905     0.023620  ...   \n",
       "...         ...            ...           ...         ...          ...  ...   \n",
       "1369  -0.000017      -0.000039  2.578090e+07    1.340988     1.287375  ...   \n",
       "1370   0.000243      -0.000017  1.131361e+08    1.352951     1.287734  ...   \n",
       "1371   0.000230       0.000013  8.402275e+07    1.402332     1.288290  ...   \n",
       "1372  -0.000082       0.000046  1.635093e+06    1.351087     1.296258  ...   \n",
       "1373   0.000021       0.000100 -5.045959e+07    1.363738     1.326553  ...   \n",
       "\n",
       "      momentum_stoch_signal  momentum_wr  momentum_ao  momentum_kama  \\\n",
       "1                 33.646631   -91.634039     0.000000       0.023924   \n",
       "2                 28.895217   -80.607609     0.000000       0.023097   \n",
       "3                 14.258188   -84.983787     0.000000       0.022416   \n",
       "4                 11.979427   -98.470322     0.000000       0.020876   \n",
       "5                 14.393974   -73.363969    -0.000615       0.020903   \n",
       "...                     ...          ...          ...            ...   \n",
       "1369              74.826267   -14.425005    -0.130026       1.413802   \n",
       "1370              80.572709   -11.705474    -0.111837       1.413342   \n",
       "1371              88.876266    -7.240723    -0.092363       1.415273   \n",
       "1372              87.651515   -18.099257    -0.068013       1.414355   \n",
       "1373              84.947809   -19.816594    -0.041889       1.414740   \n",
       "\n",
       "      momentum_roc  momentum_ppo  momentum_ppo_signal  momentum_ppo_hist  \\\n",
       "1         0.000000     -5.934792            -1.186958          -4.747833   \n",
       "2         0.000000    -12.455387            -3.440644          -9.014743   \n",
       "3         0.000000    -18.898524            -6.532220         -12.366304   \n",
       "4         0.000000    -24.170970           -10.059970         -14.111000   \n",
       "5         0.000000    -28.900125           -13.828001         -15.072124   \n",
       "...            ...           ...                  ...                ...   \n",
       "1369     -2.434291    -14.631161           -12.570468          -2.060693   \n",
       "1370     19.478555    -15.794977           -13.215370          -2.579607   \n",
       "1371     26.440825    -17.309043           -14.034104          -3.274938   \n",
       "1372     12.132075    -18.599922           -14.947268          -3.652654   \n",
       "1373      4.569426    -20.480104           -16.053835          -4.426268   \n",
       "\n",
       "        others_cr   Returns  \n",
       "1      -19.728669 -0.197287  \n",
       "2      -15.426236  0.053599  \n",
       "3      -17.133788 -0.020190  \n",
       "4      -28.508237 -0.137263  \n",
       "5      -19.246254  0.129553  \n",
       "...           ...       ...  \n",
       "1369  5277.170314  0.044014  \n",
       "1370  5325.137984  0.008921  \n",
       "1371  5523.151544  0.036499  \n",
       "1372  5317.665228 -0.036543  \n",
       "1373  5368.392753  0.009363  \n",
       "\n",
       "[1373 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the returns \n",
    "\n",
    "Cardano[\"Returns\"] = Cardano[\"Close\"].pct_change()\n",
    "\n",
    "# keep only the relevant columns, ie. the ta indicators and the returns. \n",
    "\n",
    "Cardano = Cardano[indicators].join(Cardano[\"Returns\"]).drop(0) #drop the first row as return = NaN\n",
    "\n",
    "Cardano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991616</td>\n",
       "      <td>0.137211</td>\n",
       "      <td>0.272162</td>\n",
       "      <td>-0.001385</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>0.161555</td>\n",
       "      <td>-0.188130</td>\n",
       "      <td>0.923399</td>\n",
       "      <td>0.817586</td>\n",
       "      <td>0.924717</td>\n",
       "      <td>0.902218</td>\n",
       "      <td>0.929065</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>0.079096</td>\n",
       "      <td>0.037910</td>\n",
       "      <td>-0.058878</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.916859</td>\n",
       "      <td>0.932401</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>0.068387</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.111815</td>\n",
       "      <td>0.928647</td>\n",
       "      <td>0.892273</td>\n",
       "      <td>0.915440</td>\n",
       "      <td>0.065638</td>\n",
       "      <td>0.108867</td>\n",
       "      <td>-0.033242</td>\n",
       "      <td>0.355004</td>\n",
       "      <td>0.409372</td>\n",
       "      <td>-0.099374</td>\n",
       "      <td>0.925770</td>\n",
       "      <td>0.922350</td>\n",
       "      <td>0.927924</td>\n",
       "      <td>0.926570</td>\n",
       "      <td>-0.043864</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059443</td>\n",
       "      <td>0.091781</td>\n",
       "      <td>0.143903</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>-0.053378</td>\n",
       "      <td>0.037928</td>\n",
       "      <td>0.049532</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>0.922328</td>\n",
       "      <td>0.910466</td>\n",
       "      <td>0.918758</td>\n",
       "      <td>0.889791</td>\n",
       "      <td>0.859098</td>\n",
       "      <td>0.812215</td>\n",
       "      <td>0.090722</td>\n",
       "      <td>-0.137415</td>\n",
       "      <td>0.127765</td>\n",
       "      <td>0.895907</td>\n",
       "      <td>0.908963</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.078584</td>\n",
       "      <td>0.165275</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.008129</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>0.149050</td>\n",
       "      <td>0.111505</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.111505</td>\n",
       "      <td>0.259194</td>\n",
       "      <td>0.919366</td>\n",
       "      <td>0.020284</td>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>-0.040082</td>\n",
       "      <td>0.923848</td>\n",
       "      <td>0.015572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143177</td>\n",
       "      <td>0.288398</td>\n",
       "      <td>0.026797</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.182157</td>\n",
       "      <td>-0.174099</td>\n",
       "      <td>0.928693</td>\n",
       "      <td>0.825633</td>\n",
       "      <td>0.928212</td>\n",
       "      <td>0.907849</td>\n",
       "      <td>0.929031</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.094202</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>-0.061628</td>\n",
       "      <td>0.931037</td>\n",
       "      <td>0.923114</td>\n",
       "      <td>0.936538</td>\n",
       "      <td>0.199662</td>\n",
       "      <td>0.083071</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>-0.113159</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.898686</td>\n",
       "      <td>0.920931</td>\n",
       "      <td>0.076211</td>\n",
       "      <td>0.119081</td>\n",
       "      <td>-0.036323</td>\n",
       "      <td>0.359782</td>\n",
       "      <td>0.400995</td>\n",
       "      <td>-0.056961</td>\n",
       "      <td>0.930804</td>\n",
       "      <td>0.925660</td>\n",
       "      <td>0.933768</td>\n",
       "      <td>0.932154</td>\n",
       "      <td>-0.037365</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074730</td>\n",
       "      <td>0.104898</td>\n",
       "      <td>0.142283</td>\n",
       "      <td>0.118771</td>\n",
       "      <td>0.092522</td>\n",
       "      <td>-0.063569</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.047508</td>\n",
       "      <td>-0.032725</td>\n",
       "      <td>0.928635</td>\n",
       "      <td>0.916397</td>\n",
       "      <td>0.924892</td>\n",
       "      <td>0.900214</td>\n",
       "      <td>0.871671</td>\n",
       "      <td>0.824663</td>\n",
       "      <td>0.099649</td>\n",
       "      <td>-0.138994</td>\n",
       "      <td>0.133686</td>\n",
       "      <td>0.898568</td>\n",
       "      <td>0.910593</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.012503</td>\n",
       "      <td>-0.063454</td>\n",
       "      <td>0.173674</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.214412</td>\n",
       "      <td>0.157682</td>\n",
       "      <td>0.123664</td>\n",
       "      <td>0.130524</td>\n",
       "      <td>0.123664</td>\n",
       "      <td>0.269463</td>\n",
       "      <td>0.925087</td>\n",
       "      <td>0.034636</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>-0.019748</td>\n",
       "      <td>0.933497</td>\n",
       "      <td>0.022876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137211</td>\n",
       "      <td>0.143177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205898</td>\n",
       "      <td>0.631143</td>\n",
       "      <td>0.065272</td>\n",
       "      <td>0.158278</td>\n",
       "      <td>0.178089</td>\n",
       "      <td>0.023198</td>\n",
       "      <td>0.118190</td>\n",
       "      <td>0.178131</td>\n",
       "      <td>0.084890</td>\n",
       "      <td>0.132067</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.291675</td>\n",
       "      <td>0.643652</td>\n",
       "      <td>0.354215</td>\n",
       "      <td>-0.198809</td>\n",
       "      <td>0.121766</td>\n",
       "      <td>0.134685</td>\n",
       "      <td>0.104261</td>\n",
       "      <td>0.243983</td>\n",
       "      <td>0.572973</td>\n",
       "      <td>0.456803</td>\n",
       "      <td>-0.383653</td>\n",
       "      <td>0.025583</td>\n",
       "      <td>0.128859</td>\n",
       "      <td>0.093765</td>\n",
       "      <td>0.288092</td>\n",
       "      <td>0.713369</td>\n",
       "      <td>-0.472395</td>\n",
       "      <td>0.444279</td>\n",
       "      <td>0.396626</td>\n",
       "      <td>0.240121</td>\n",
       "      <td>0.117663</td>\n",
       "      <td>0.063297</td>\n",
       "      <td>0.119983</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>0.271180</td>\n",
       "      <td>0.661179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606498</td>\n",
       "      <td>0.694681</td>\n",
       "      <td>0.561668</td>\n",
       "      <td>0.453935</td>\n",
       "      <td>0.623906</td>\n",
       "      <td>-0.128848</td>\n",
       "      <td>0.437287</td>\n",
       "      <td>0.392812</td>\n",
       "      <td>0.205564</td>\n",
       "      <td>0.130137</td>\n",
       "      <td>0.079897</td>\n",
       "      <td>0.105272</td>\n",
       "      <td>0.059864</td>\n",
       "      <td>-0.039796</td>\n",
       "      <td>-0.048290</td>\n",
       "      <td>0.613626</td>\n",
       "      <td>-0.597999</td>\n",
       "      <td>0.679578</td>\n",
       "      <td>0.097725</td>\n",
       "      <td>0.071701</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>0.415154</td>\n",
       "      <td>0.761574</td>\n",
       "      <td>0.224603</td>\n",
       "      <td>0.242235</td>\n",
       "      <td>0.254723</td>\n",
       "      <td>0.701723</td>\n",
       "      <td>0.773482</td>\n",
       "      <td>0.630210</td>\n",
       "      <td>0.653835</td>\n",
       "      <td>0.630210</td>\n",
       "      <td>0.437311</td>\n",
       "      <td>0.132801</td>\n",
       "      <td>0.472011</td>\n",
       "      <td>0.550493</td>\n",
       "      <td>0.552061</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>0.166842</td>\n",
       "      <td>0.265361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272162</td>\n",
       "      <td>0.288398</td>\n",
       "      <td>0.205898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158534</td>\n",
       "      <td>0.072426</td>\n",
       "      <td>0.127015</td>\n",
       "      <td>0.649043</td>\n",
       "      <td>-0.041502</td>\n",
       "      <td>0.219480</td>\n",
       "      <td>0.140171</td>\n",
       "      <td>0.188016</td>\n",
       "      <td>0.215105</td>\n",
       "      <td>0.138363</td>\n",
       "      <td>0.125198</td>\n",
       "      <td>0.246977</td>\n",
       "      <td>0.241013</td>\n",
       "      <td>-0.044858</td>\n",
       "      <td>0.225691</td>\n",
       "      <td>0.217476</td>\n",
       "      <td>0.235245</td>\n",
       "      <td>0.070606</td>\n",
       "      <td>0.212819</td>\n",
       "      <td>0.217332</td>\n",
       "      <td>-0.112629</td>\n",
       "      <td>0.197687</td>\n",
       "      <td>0.217340</td>\n",
       "      <td>0.212884</td>\n",
       "      <td>0.120984</td>\n",
       "      <td>0.220524</td>\n",
       "      <td>-0.152161</td>\n",
       "      <td>0.493420</td>\n",
       "      <td>0.351791</td>\n",
       "      <td>0.546137</td>\n",
       "      <td>0.218068</td>\n",
       "      <td>0.173856</td>\n",
       "      <td>0.234176</td>\n",
       "      <td>0.193902</td>\n",
       "      <td>0.060050</td>\n",
       "      <td>0.218530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191045</td>\n",
       "      <td>0.207756</td>\n",
       "      <td>0.178017</td>\n",
       "      <td>0.111872</td>\n",
       "      <td>0.236387</td>\n",
       "      <td>-0.254530</td>\n",
       "      <td>0.108451</td>\n",
       "      <td>0.093845</td>\n",
       "      <td>0.065995</td>\n",
       "      <td>0.258623</td>\n",
       "      <td>0.188868</td>\n",
       "      <td>0.224301</td>\n",
       "      <td>0.158615</td>\n",
       "      <td>0.114121</td>\n",
       "      <td>0.084665</td>\n",
       "      <td>0.179137</td>\n",
       "      <td>-0.128980</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.137259</td>\n",
       "      <td>0.101103</td>\n",
       "      <td>0.024886</td>\n",
       "      <td>-0.050957</td>\n",
       "      <td>0.157631</td>\n",
       "      <td>0.281940</td>\n",
       "      <td>0.160430</td>\n",
       "      <td>0.149714</td>\n",
       "      <td>0.128060</td>\n",
       "      <td>0.229784</td>\n",
       "      <td>0.203014</td>\n",
       "      <td>0.218121</td>\n",
       "      <td>0.213223</td>\n",
       "      <td>0.218121</td>\n",
       "      <td>0.467322</td>\n",
       "      <td>0.225637</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>0.134625</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.332831</td>\n",
       "      <td>0.146707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001385</td>\n",
       "      <td>0.026797</td>\n",
       "      <td>0.631143</td>\n",
       "      <td>0.158534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062934</td>\n",
       "      <td>0.269490</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>0.122802</td>\n",
       "      <td>-0.003668</td>\n",
       "      <td>0.022963</td>\n",
       "      <td>-0.040120</td>\n",
       "      <td>-0.009406</td>\n",
       "      <td>-0.087773</td>\n",
       "      <td>0.297207</td>\n",
       "      <td>0.772744</td>\n",
       "      <td>0.442058</td>\n",
       "      <td>-0.197077</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>-0.008117</td>\n",
       "      <td>0.188365</td>\n",
       "      <td>0.651756</td>\n",
       "      <td>0.514087</td>\n",
       "      <td>-0.404487</td>\n",
       "      <td>-0.060297</td>\n",
       "      <td>-0.001210</td>\n",
       "      <td>-0.022152</td>\n",
       "      <td>0.300022</td>\n",
       "      <td>0.776434</td>\n",
       "      <td>-0.484524</td>\n",
       "      <td>0.363505</td>\n",
       "      <td>0.269767</td>\n",
       "      <td>0.368944</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.191676</td>\n",
       "      <td>0.763723</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758797</td>\n",
       "      <td>0.891408</td>\n",
       "      <td>0.465269</td>\n",
       "      <td>0.353762</td>\n",
       "      <td>0.763807</td>\n",
       "      <td>-0.220948</td>\n",
       "      <td>0.377306</td>\n",
       "      <td>0.288109</td>\n",
       "      <td>0.390790</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>-0.053551</td>\n",
       "      <td>-0.116727</td>\n",
       "      <td>-0.131126</td>\n",
       "      <td>0.620744</td>\n",
       "      <td>-0.558948</td>\n",
       "      <td>0.661848</td>\n",
       "      <td>-0.020469</td>\n",
       "      <td>-0.055702</td>\n",
       "      <td>-0.028379</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.656401</td>\n",
       "      <td>0.786905</td>\n",
       "      <td>0.436697</td>\n",
       "      <td>0.529047</td>\n",
       "      <td>0.570880</td>\n",
       "      <td>0.628818</td>\n",
       "      <td>0.657315</td>\n",
       "      <td>0.737902</td>\n",
       "      <td>0.804068</td>\n",
       "      <td>0.737902</td>\n",
       "      <td>0.389050</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.610914</td>\n",
       "      <td>0.521831</td>\n",
       "      <td>0.428455</td>\n",
       "      <td>0.345720</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.222746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.006807</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.550493</td>\n",
       "      <td>0.134625</td>\n",
       "      <td>0.521831</td>\n",
       "      <td>0.042081</td>\n",
       "      <td>0.102928</td>\n",
       "      <td>0.117090</td>\n",
       "      <td>-0.153037</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>0.100563</td>\n",
       "      <td>-0.018055</td>\n",
       "      <td>0.030552</td>\n",
       "      <td>-0.095021</td>\n",
       "      <td>0.414538</td>\n",
       "      <td>0.500423</td>\n",
       "      <td>0.369596</td>\n",
       "      <td>-0.055696</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.031471</td>\n",
       "      <td>-0.011207</td>\n",
       "      <td>0.360057</td>\n",
       "      <td>0.455263</td>\n",
       "      <td>0.432244</td>\n",
       "      <td>-0.204841</td>\n",
       "      <td>-0.065832</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.389907</td>\n",
       "      <td>0.499678</td>\n",
       "      <td>-0.338012</td>\n",
       "      <td>0.385366</td>\n",
       "      <td>0.351829</td>\n",
       "      <td>0.183715</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>-0.037894</td>\n",
       "      <td>0.011188</td>\n",
       "      <td>-0.026511</td>\n",
       "      <td>0.395709</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492780</td>\n",
       "      <td>0.566742</td>\n",
       "      <td>0.517880</td>\n",
       "      <td>0.629086</td>\n",
       "      <td>0.505584</td>\n",
       "      <td>-0.145538</td>\n",
       "      <td>0.438874</td>\n",
       "      <td>0.398990</td>\n",
       "      <td>0.186356</td>\n",
       "      <td>0.023886</td>\n",
       "      <td>-0.010962</td>\n",
       "      <td>0.006468</td>\n",
       "      <td>-0.052211</td>\n",
       "      <td>-0.165620</td>\n",
       "      <td>-0.194920</td>\n",
       "      <td>0.611027</td>\n",
       "      <td>-0.339300</td>\n",
       "      <td>0.534027</td>\n",
       "      <td>-0.008834</td>\n",
       "      <td>-0.030965</td>\n",
       "      <td>-0.015305</td>\n",
       "      <td>0.038608</td>\n",
       "      <td>0.356436</td>\n",
       "      <td>0.597996</td>\n",
       "      <td>0.189017</td>\n",
       "      <td>0.257856</td>\n",
       "      <td>0.297208</td>\n",
       "      <td>0.685958</td>\n",
       "      <td>0.506581</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.510693</td>\n",
       "      <td>0.454119</td>\n",
       "      <td>0.379165</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.529765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>0.461077</td>\n",
       "      <td>0.050201</td>\n",
       "      <td>0.178653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>0.552061</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>0.428455</td>\n",
       "      <td>-0.003811</td>\n",
       "      <td>0.093572</td>\n",
       "      <td>0.069426</td>\n",
       "      <td>-0.164909</td>\n",
       "      <td>0.042908</td>\n",
       "      <td>0.142665</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.067767</td>\n",
       "      <td>-0.074607</td>\n",
       "      <td>0.442019</td>\n",
       "      <td>0.385044</td>\n",
       "      <td>0.183762</td>\n",
       "      <td>-0.070316</td>\n",
       "      <td>0.045281</td>\n",
       "      <td>0.065641</td>\n",
       "      <td>0.018458</td>\n",
       "      <td>0.358443</td>\n",
       "      <td>0.296087</td>\n",
       "      <td>0.252324</td>\n",
       "      <td>-0.196182</td>\n",
       "      <td>-0.047852</td>\n",
       "      <td>0.073098</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>0.375858</td>\n",
       "      <td>0.429295</td>\n",
       "      <td>-0.330003</td>\n",
       "      <td>0.418955</td>\n",
       "      <td>0.414463</td>\n",
       "      <td>0.099015</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>-0.008293</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.418212</td>\n",
       "      <td>0.539628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.431276</td>\n",
       "      <td>0.507782</td>\n",
       "      <td>0.615257</td>\n",
       "      <td>0.683875</td>\n",
       "      <td>0.375836</td>\n",
       "      <td>-0.107570</td>\n",
       "      <td>0.517160</td>\n",
       "      <td>0.484306</td>\n",
       "      <td>0.160198</td>\n",
       "      <td>0.051539</td>\n",
       "      <td>0.018102</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>-0.030806</td>\n",
       "      <td>-0.155767</td>\n",
       "      <td>-0.194175</td>\n",
       "      <td>0.571516</td>\n",
       "      <td>-0.394807</td>\n",
       "      <td>0.542630</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>0.053490</td>\n",
       "      <td>0.253763</td>\n",
       "      <td>0.545713</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>0.075494</td>\n",
       "      <td>0.132287</td>\n",
       "      <td>0.717858</td>\n",
       "      <td>0.423339</td>\n",
       "      <td>0.361927</td>\n",
       "      <td>0.424137</td>\n",
       "      <td>0.361927</td>\n",
       "      <td>0.402567</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.480614</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.070525</td>\n",
       "      <td>0.077630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.040082</td>\n",
       "      <td>-0.019748</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.345720</td>\n",
       "      <td>0.111527</td>\n",
       "      <td>0.048433</td>\n",
       "      <td>0.135816</td>\n",
       "      <td>-0.015794</td>\n",
       "      <td>-0.062837</td>\n",
       "      <td>-0.064413</td>\n",
       "      <td>-0.072844</td>\n",
       "      <td>-0.072824</td>\n",
       "      <td>-0.070390</td>\n",
       "      <td>0.052978</td>\n",
       "      <td>0.387865</td>\n",
       "      <td>0.505860</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.065934</td>\n",
       "      <td>-0.067735</td>\n",
       "      <td>0.101579</td>\n",
       "      <td>0.471063</td>\n",
       "      <td>0.510026</td>\n",
       "      <td>-0.074669</td>\n",
       "      <td>-0.057134</td>\n",
       "      <td>-0.062141</td>\n",
       "      <td>-0.061084</td>\n",
       "      <td>0.136824</td>\n",
       "      <td>0.289551</td>\n",
       "      <td>-0.109520</td>\n",
       "      <td>0.031716</td>\n",
       "      <td>-0.040749</td>\n",
       "      <td>0.234717</td>\n",
       "      <td>-0.068407</td>\n",
       "      <td>-0.074865</td>\n",
       "      <td>-0.061382</td>\n",
       "      <td>-0.066751</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.415536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268313</td>\n",
       "      <td>0.282910</td>\n",
       "      <td>-0.071282</td>\n",
       "      <td>0.051865</td>\n",
       "      <td>0.420603</td>\n",
       "      <td>-0.122426</td>\n",
       "      <td>-0.051170</td>\n",
       "      <td>-0.077362</td>\n",
       "      <td>0.107790</td>\n",
       "      <td>-0.053791</td>\n",
       "      <td>-0.066356</td>\n",
       "      <td>-0.060232</td>\n",
       "      <td>-0.060893</td>\n",
       "      <td>-0.066591</td>\n",
       "      <td>-0.054710</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>-0.046493</td>\n",
       "      <td>-0.087241</td>\n",
       "      <td>0.061275</td>\n",
       "      <td>-0.021936</td>\n",
       "      <td>0.320945</td>\n",
       "      <td>0.276863</td>\n",
       "      <td>0.429201</td>\n",
       "      <td>0.467856</td>\n",
       "      <td>0.440544</td>\n",
       "      <td>0.117263</td>\n",
       "      <td>0.319471</td>\n",
       "      <td>0.324697</td>\n",
       "      <td>0.327817</td>\n",
       "      <td>0.324697</td>\n",
       "      <td>0.052238</td>\n",
       "      <td>-0.061853</td>\n",
       "      <td>0.251452</td>\n",
       "      <td>0.461077</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030643</td>\n",
       "      <td>0.268932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.923848</td>\n",
       "      <td>0.933497</td>\n",
       "      <td>0.166842</td>\n",
       "      <td>0.332831</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>0.188574</td>\n",
       "      <td>-0.037256</td>\n",
       "      <td>0.987696</td>\n",
       "      <td>0.919407</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>0.982260</td>\n",
       "      <td>0.939716</td>\n",
       "      <td>0.154156</td>\n",
       "      <td>0.098215</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>-0.074226</td>\n",
       "      <td>0.987991</td>\n",
       "      <td>0.985678</td>\n",
       "      <td>0.985868</td>\n",
       "      <td>0.350277</td>\n",
       "      <td>0.091574</td>\n",
       "      <td>0.031367</td>\n",
       "      <td>-0.104410</td>\n",
       "      <td>0.956482</td>\n",
       "      <td>0.981215</td>\n",
       "      <td>0.983764</td>\n",
       "      <td>0.251959</td>\n",
       "      <td>0.103049</td>\n",
       "      <td>0.060175</td>\n",
       "      <td>0.478425</td>\n",
       "      <td>0.520138</td>\n",
       "      <td>-0.034508</td>\n",
       "      <td>0.986631</td>\n",
       "      <td>0.971887</td>\n",
       "      <td>0.990585</td>\n",
       "      <td>0.979307</td>\n",
       "      <td>0.051322</td>\n",
       "      <td>0.095790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082236</td>\n",
       "      <td>0.115555</td>\n",
       "      <td>0.255884</td>\n",
       "      <td>0.182999</td>\n",
       "      <td>0.099241</td>\n",
       "      <td>-0.094919</td>\n",
       "      <td>0.223063</td>\n",
       "      <td>0.258647</td>\n",
       "      <td>-0.139843</td>\n",
       "      <td>0.992212</td>\n",
       "      <td>0.978024</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.952765</td>\n",
       "      <td>0.887564</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.101849</td>\n",
       "      <td>-0.144697</td>\n",
       "      <td>0.138105</td>\n",
       "      <td>0.935592</td>\n",
       "      <td>0.944793</td>\n",
       "      <td>-0.005581</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>-0.077448</td>\n",
       "      <td>0.198271</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>-0.007536</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.256203</td>\n",
       "      <td>0.167078</td>\n",
       "      <td>0.111653</td>\n",
       "      <td>0.120193</td>\n",
       "      <td>0.111653</td>\n",
       "      <td>0.374799</td>\n",
       "      <td>0.988568</td>\n",
       "      <td>0.106569</td>\n",
       "      <td>0.050201</td>\n",
       "      <td>0.070525</td>\n",
       "      <td>-0.030643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.265361</td>\n",
       "      <td>0.146707</td>\n",
       "      <td>0.222746</td>\n",
       "      <td>0.321814</td>\n",
       "      <td>0.091488</td>\n",
       "      <td>0.270997</td>\n",
       "      <td>0.118649</td>\n",
       "      <td>-0.006975</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>-0.013506</td>\n",
       "      <td>-0.006405</td>\n",
       "      <td>-0.024380</td>\n",
       "      <td>0.154254</td>\n",
       "      <td>0.417175</td>\n",
       "      <td>0.363020</td>\n",
       "      <td>-0.219828</td>\n",
       "      <td>-0.010852</td>\n",
       "      <td>-0.008722</td>\n",
       "      <td>-0.013577</td>\n",
       "      <td>0.159065</td>\n",
       "      <td>0.514416</td>\n",
       "      <td>0.346538</td>\n",
       "      <td>-0.266165</td>\n",
       "      <td>-0.020718</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.007355</td>\n",
       "      <td>0.234023</td>\n",
       "      <td>0.360072</td>\n",
       "      <td>-0.069645</td>\n",
       "      <td>0.072249</td>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.120659</td>\n",
       "      <td>-0.010161</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>-0.006918</td>\n",
       "      <td>-0.014314</td>\n",
       "      <td>0.066342</td>\n",
       "      <td>0.318870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219156</td>\n",
       "      <td>0.197529</td>\n",
       "      <td>0.105799</td>\n",
       "      <td>0.080923</td>\n",
       "      <td>0.367597</td>\n",
       "      <td>-0.015968</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>-0.004263</td>\n",
       "      <td>-0.014753</td>\n",
       "      <td>-0.031704</td>\n",
       "      <td>-0.035872</td>\n",
       "      <td>0.153316</td>\n",
       "      <td>-0.115666</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>-0.017060</td>\n",
       "      <td>-0.020731</td>\n",
       "      <td>0.189185</td>\n",
       "      <td>-0.154745</td>\n",
       "      <td>0.123012</td>\n",
       "      <td>0.359048</td>\n",
       "      <td>0.389692</td>\n",
       "      <td>0.172654</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.130831</td>\n",
       "      <td>0.357758</td>\n",
       "      <td>0.392105</td>\n",
       "      <td>0.197171</td>\n",
       "      <td>0.392105</td>\n",
       "      <td>0.047123</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>0.275074</td>\n",
       "      <td>0.178653</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.268932</td>\n",
       "      <td>0.040387</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000  0.991616  0.137211  0.272162 -0.001385  0.000883 -0.005073   \n",
       "1   0.991616  1.000000  0.143177  0.288398  0.026797  0.001537  0.000413   \n",
       "2   0.137211  0.143177  1.000000  0.205898  0.631143  0.065272  0.158278   \n",
       "3   0.272162  0.288398  0.205898  1.000000  0.158534  0.072426  0.127015   \n",
       "4  -0.001385  0.026797  0.631143  0.158534  1.000000  0.062934  0.269490   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77 -0.006807  0.002200  0.550493  0.134625  0.521831  0.042081  0.102928   \n",
       "78  0.010725  0.011532  0.552061  0.097358  0.428455 -0.003811  0.093572   \n",
       "79 -0.040082 -0.019748  0.146507  0.117925  0.345720  0.111527  0.048433   \n",
       "80  0.923848  0.933497  0.166842  0.332831  0.051843  0.008064  0.013979   \n",
       "81  0.015572  0.022876  0.265361  0.146707  0.222746  0.321814  0.091488   \n",
       "\n",
       "          7         8         9         10        11        12        13  \\\n",
       "0   0.161555 -0.188130  0.923399  0.817586  0.924717  0.902218  0.929065   \n",
       "1   0.182157 -0.174099  0.928693  0.825633  0.928212  0.907849  0.929031   \n",
       "2   0.178089  0.023198  0.118190  0.178131  0.084890  0.132067  0.006693   \n",
       "3   0.649043 -0.041502  0.219480  0.140171  0.188016  0.215105  0.138363   \n",
       "4   0.148458  0.122802 -0.003668  0.022963 -0.040120 -0.009406 -0.087773   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.117090 -0.153037  0.012525  0.100563 -0.018055  0.030552 -0.095021   \n",
       "78  0.069426 -0.164909  0.042908  0.142665  0.013098  0.067767 -0.074607   \n",
       "79  0.135816 -0.015794 -0.062837 -0.064413 -0.072844 -0.072824 -0.070390   \n",
       "80  0.188574 -0.037256  0.987696  0.919407  0.978741  0.982260  0.939716   \n",
       "81  0.270997  0.118649 -0.006975  0.004507 -0.013506 -0.006405 -0.024380   \n",
       "\n",
       "          14        15        16        17        18        19        20  \\\n",
       "0  -0.006289  0.079096  0.037910 -0.058878  0.925689  0.916859  0.932401   \n",
       "1   0.004620  0.094202  0.061432 -0.061628  0.931037  0.923114  0.936538   \n",
       "2   0.291675  0.643652  0.354215 -0.198809  0.121766  0.134685  0.104261   \n",
       "3   0.125198  0.246977  0.241013 -0.044858  0.225691  0.217476  0.235245   \n",
       "4   0.297207  0.772744  0.442058 -0.197077  0.000851  0.007714 -0.008117   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.414538  0.500423  0.369596 -0.055696  0.012992  0.031471 -0.011207   \n",
       "78  0.442019  0.385044  0.183762 -0.070316  0.045281  0.065641  0.018458   \n",
       "79  0.052978  0.387865  0.505860  0.016709 -0.066866 -0.065934 -0.067735   \n",
       "80  0.154156  0.098215  0.073120 -0.074226  0.987991  0.985678  0.985868   \n",
       "81  0.154254  0.417175  0.363020 -0.219828 -0.010852 -0.008722 -0.013577   \n",
       "\n",
       "          21        22        23        24        25        26        27  \\\n",
       "0   0.189943  0.068387  0.000361 -0.111815  0.928647  0.892273  0.915440   \n",
       "1   0.199662  0.083071  0.016138 -0.113159  0.932246  0.898686  0.920931   \n",
       "2   0.243983  0.572973  0.456803 -0.383653  0.025583  0.128859  0.093765   \n",
       "3   0.070606  0.212819  0.217332 -0.112629  0.197687  0.217340  0.212884   \n",
       "4   0.188365  0.651756  0.514087 -0.404487 -0.060297 -0.001210 -0.022152   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.360057  0.455263  0.432244 -0.204841 -0.065832  0.039647  0.002745   \n",
       "78  0.358443  0.296087  0.252324 -0.196182 -0.047852  0.073098  0.031102   \n",
       "79  0.101579  0.471063  0.510026 -0.074669 -0.057134 -0.062141 -0.061084   \n",
       "80  0.350277  0.091574  0.031367 -0.104410  0.956482  0.981215  0.983764   \n",
       "81  0.159065  0.514416  0.346538 -0.266165 -0.020718 -0.000026 -0.007355   \n",
       "\n",
       "          28        29        30        31        32        33        34  \\\n",
       "0   0.065638  0.108867 -0.033242  0.355004  0.409372 -0.099374  0.925770   \n",
       "1   0.076211  0.119081 -0.036323  0.359782  0.400995 -0.056961  0.930804   \n",
       "2   0.288092  0.713369 -0.472395  0.444279  0.396626  0.240121  0.117663   \n",
       "3   0.120984  0.220524 -0.152161  0.493420  0.351791  0.546137  0.218068   \n",
       "4   0.300022  0.776434 -0.484524  0.363505  0.269767  0.368944 -0.006248   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.389907  0.499678 -0.338012  0.385366  0.351829  0.183715  0.008828   \n",
       "78  0.375858  0.429295 -0.330003  0.418955  0.414463  0.099015  0.041304   \n",
       "79  0.136824  0.289551 -0.109520  0.031716 -0.040749  0.234717 -0.068407   \n",
       "80  0.251959  0.103049  0.060175  0.478425  0.520138 -0.034508  0.986631   \n",
       "81  0.234023  0.360072 -0.069645  0.072249  0.038595  0.120659 -0.010161   \n",
       "\n",
       "          35        36        37        38        39  ...        42        43  \\\n",
       "0   0.922350  0.927924  0.926570 -0.043864  0.000824  ... -0.059443  0.091781   \n",
       "1   0.925660  0.933768  0.932154 -0.037365  0.011869  ... -0.074730  0.104898   \n",
       "2   0.063297  0.119983  0.080415  0.271180  0.661179  ... -0.606498  0.694681   \n",
       "3   0.173856  0.234176  0.193902  0.060050  0.218530  ... -0.191045  0.207756   \n",
       "4  -0.054841 -0.000686 -0.036656  0.191676  0.763723  ... -0.758797  0.891408   \n",
       "..       ...       ...       ...       ...       ...  ...       ...       ...   \n",
       "77 -0.037894  0.011188 -0.026511  0.395709  0.649123  ... -0.492780  0.566742   \n",
       "78 -0.008293  0.040737  0.000791  0.418212  0.539628  ... -0.431276  0.507782   \n",
       "79 -0.074865 -0.061382 -0.066751  0.058705  0.415536  ... -0.268313  0.282910   \n",
       "80  0.971887  0.990585  0.979307  0.051322  0.095790  ... -0.082236  0.115555   \n",
       "81 -0.017334 -0.006918 -0.014314  0.066342  0.318870  ... -0.219156  0.197529   \n",
       "\n",
       "          44        45        46        47        48        49        50  \\\n",
       "0   0.143903  0.120853  0.076848 -0.053378  0.037928  0.049532 -0.047097   \n",
       "1   0.142283  0.118771  0.092522 -0.063569  0.039312  0.047508 -0.032725   \n",
       "2   0.561668  0.453935  0.623906 -0.128848  0.437287  0.392812  0.205564   \n",
       "3   0.178017  0.111872  0.236387 -0.254530  0.108451  0.093845  0.065995   \n",
       "4   0.465269  0.353762  0.763807 -0.220948  0.377306  0.288109  0.390790   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.517880  0.629086  0.505584 -0.145538  0.438874  0.398990  0.186356   \n",
       "78  0.615257  0.683875  0.375836 -0.107570  0.517160  0.484306  0.160198   \n",
       "79 -0.071282  0.051865  0.420603 -0.122426 -0.051170 -0.077362  0.107790   \n",
       "80  0.255884  0.182999  0.099241 -0.094919  0.223063  0.258647 -0.139843   \n",
       "81  0.105799  0.080923  0.367597 -0.015968  0.121166  0.106000  0.068895   \n",
       "\n",
       "          51        52        53        54        55        56        57  \\\n",
       "0   0.922328  0.910466  0.918758  0.889791  0.859098  0.812215  0.090722   \n",
       "1   0.928635  0.916397  0.924892  0.900214  0.871671  0.824663  0.099649   \n",
       "2   0.130137  0.079897  0.105272  0.059864 -0.039796 -0.048290  0.613626   \n",
       "3   0.258623  0.188868  0.224301  0.158615  0.114121  0.084665  0.179137   \n",
       "4   0.015903 -0.032827 -0.008500 -0.053551 -0.116727 -0.131126  0.620744   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.023886 -0.010962  0.006468 -0.052211 -0.165620 -0.194920  0.611027   \n",
       "78  0.051539  0.018102  0.034900 -0.030806 -0.155767 -0.194175  0.571516   \n",
       "79 -0.053791 -0.066356 -0.060232 -0.060893 -0.066591 -0.054710  0.252563   \n",
       "80  0.992212  0.978024  0.987655  0.952765  0.887564  0.841797  0.101849   \n",
       "81  0.001166 -0.009662 -0.004263 -0.014753 -0.031704 -0.035872  0.153316   \n",
       "\n",
       "          58        59        60        61        62        63        64  \\\n",
       "0  -0.137415  0.127765  0.895907  0.908963 -0.002297 -0.008720 -0.078584   \n",
       "1  -0.138994  0.133686  0.898568  0.910593 -0.003729 -0.012503 -0.063454   \n",
       "2  -0.597999  0.679578  0.097725  0.071701  0.004300 -0.008998  0.415154   \n",
       "3  -0.128980  0.172997  0.137259  0.101103  0.024886 -0.050957  0.157631   \n",
       "4  -0.558948  0.661848 -0.020469 -0.055702 -0.028379  0.002145  0.656401   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77 -0.339300  0.534027 -0.008834 -0.030965 -0.015305  0.038608  0.356436   \n",
       "78 -0.394807  0.542630  0.011385  0.005179 -0.045319  0.053490  0.253763   \n",
       "79  0.028623  0.126684 -0.046493 -0.087241  0.061275 -0.021936  0.320945   \n",
       "80 -0.144697  0.138105  0.935592  0.944793 -0.005581 -0.009531 -0.077448   \n",
       "81 -0.115666  0.150999 -0.017060 -0.020731  0.189185 -0.154745  0.123012   \n",
       "\n",
       "          65        66        67        68        69        70        71  \\\n",
       "0   0.165275 -0.004822 -0.006526 -0.008129  0.216467  0.149050  0.111505   \n",
       "1   0.173674  0.013634  0.013429  0.011753  0.214412  0.157682  0.123664   \n",
       "2   0.761574  0.224603  0.242235  0.254723  0.701723  0.773482  0.630210   \n",
       "3   0.281940  0.160430  0.149714  0.128060  0.229784  0.203014  0.218121   \n",
       "4   0.786905  0.436697  0.529047  0.570880  0.628818  0.657315  0.737902   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.597996  0.189017  0.257856  0.297208  0.685958  0.506581  0.454119   \n",
       "78  0.545713  0.015785  0.075494  0.132287  0.717858  0.423339  0.361927   \n",
       "79  0.276863  0.429201  0.467856  0.440544  0.117263  0.319471  0.324697   \n",
       "80  0.198271 -0.006644 -0.007536 -0.009725  0.256203  0.167078  0.111653   \n",
       "81  0.359048  0.389692  0.172654  0.079379  0.130831  0.357758  0.392105   \n",
       "\n",
       "          72        73        74        75        76        77        78  \\\n",
       "0   0.117746  0.111505  0.259194  0.919366  0.020284 -0.006807  0.010725   \n",
       "1   0.130524  0.123664  0.269463  0.925087  0.034636  0.002200  0.011532   \n",
       "2   0.653835  0.630210  0.437311  0.132801  0.472011  0.550493  0.552061   \n",
       "3   0.213223  0.218121  0.467322  0.225637  0.205292  0.134625  0.097358   \n",
       "4   0.804068  0.737902  0.389050  0.005046  0.610914  0.521831  0.428455   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "77  0.510693  0.454119  0.379165  0.022903  0.529765  1.000000  0.913444   \n",
       "78  0.424137  0.361927  0.402567  0.054131  0.480614  0.913444  1.000000   \n",
       "79  0.327817  0.324697  0.052238 -0.061853  0.251452  0.461077  0.060046   \n",
       "80  0.120193  0.111653  0.374799  0.988568  0.106569  0.050201  0.070525   \n",
       "81  0.197171  0.392105  0.047123 -0.005442  0.275074  0.178653  0.077630   \n",
       "\n",
       "          79        80        81  \n",
       "0  -0.040082  0.923848  0.015572  \n",
       "1  -0.019748  0.933497  0.022876  \n",
       "2   0.146507  0.166842  0.265361  \n",
       "3   0.117925  0.332831  0.146707  \n",
       "4   0.345720  0.051843  0.222746  \n",
       "..       ...       ...       ...  \n",
       "77  0.461077  0.050201  0.178653  \n",
       "78  0.060046  0.070525  0.077630  \n",
       "79  1.000000 -0.030643  0.268932  \n",
       "80 -0.030643  1.000000  0.040387  \n",
       "81  0.268932  0.040387  1.000000  \n",
       "\n",
       "[82 rows x 82 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the correlations between the features and the returns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", len(indicators))\n",
    "pd.DataFrame(np.corrcoef(Cardano, rowvar=False))\n",
    "\n",
    "# if a coefficient is > 0.9 , drop it\n",
    "\n",
    "#######                     #######\n",
    "####### CODE GENERALIZATION #######\n",
    "#######                     #######\n",
    "\n",
    "\n",
    "#(so far, we did it manually, not good)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "\n",
    "Cardano_train, Cardano_test = train_test_split(Cardano,train_size = 0.80,random_state=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "\n",
    "sc = StandardScaler()\n",
    "Z_Cardano_train = sc.fit_transform(Cardano_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression (alpha = 1.0)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "regLasso1 = Lasso(fit_intercept=False,normalize=False, max_iter=1000)\n",
    "#print(regLasso1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for clarity \n",
    "# We use Features from t=0 to t=T-1 to predict Returns from t=1 to t=T, where T is the final observation date\n",
    "\n",
    "X,y = pd.DataFrame(Z_Cardano_train[:-1,:-1]),pd.DataFrame(Z_Cardano_train[1:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(fit_intercept=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "\n",
    "regLasso1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24519039807387344, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3158954663642817, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3115423223838434, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27328261260856834, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28212482621233903, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3320442752252575, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4023848293886658, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4654517325919869, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5057085883940999, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4196571417512587, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.47502120461172126, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7565956682013848, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9578184854276515, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0617763905770516, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9285270964408028, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.710373129395407, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5393035337376659, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.443804828611178, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41172273203017085, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.45165403600367426, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6280111079219068, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8149663601556085, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9669715075077647, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0532876072805948, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0766825082311016, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0581432599383334, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.021324357837102, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9838147652180851, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.955001649059227, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0419709550898233, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4448452874526083, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0500683028189997, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.7374055552940035, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.418301419528916, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.442172788821722, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.243343655346166, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.271969038451743, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.89387207430093, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.405080272505415, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.090238613986457, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.864680204004571, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.640394251315, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.36453096960895, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.007239303736355, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.119580878738702, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.913554655939038, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.559614656675194, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.27292340675308, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.75986718086142, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7674137676434611, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5841312688626203, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7243523882259524, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.951852605795807, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1459026336774514, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.262068240141616, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3050352158120404, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2286777368270805, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.122414584078115, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.02025444788444, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.988286783277431, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0072000942778914, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.051865497202243, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.10375669494897, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.5963210330212405, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6765032500318284, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.014050723366495, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.444976865926037, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.81271669866112, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.980562583243795, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.866982001844349, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.454539218300852, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.852091773364236, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.05285549819223, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.073377931544314, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.988353035392947, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.703170509222446, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.76058268038571, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.693111058708382, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.576600933096756, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.455188442840267, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.331878452768478, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.439485807145616, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.35150224868346, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.278646128305354, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.731651993027299, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.838230516704925, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:517: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.538270472608474, tolerance: 0.10924551763214954\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    }
   ],
   "source": [
    "# obtain coeffficients of the LASSO regression for multiple alphas\n",
    "\n",
    "from sklearn.linear_model import lasso_path\n",
    "alpha_for_path, coefs_lasso, _ = lasso_path(X,y,n_alphas=500)#,alphas=my_alphas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# graph of lasso path (coefficients given alpha)\n",
    "import matplotlib.cm as cm\n",
    "couleurs = cm.rainbow(np.linspace(0,1,83))\n",
    "for i in range(coefs_lasso.shape[1]):\n",
    "    plt.plot(alpha_for_path,coefs_lasso[0][i,:],c=couleurs[i])\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso path')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of non-nul coefficients for each alpha\n",
    "\n",
    "nbNonZero = np.apply_along_axis(func1d=np.count_nonzero,arr=coefs_lasso[0],axis=0)\n",
    "alphas_nnz_df = pd.DataFrame({'alpha':alpha_for_path,'Nb non-zero coefs':nbNonZero})\n",
    "\n",
    "plt.plot(alpha_for_path,nbNonZero)\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Nb. coef') \n",
    "plt.title('Nb. non-nul coef vs. Alpha') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the alpha for which we get 8 selected features (and its index)\n",
    "\n",
    "alphas_to_get_8_features = alphas_nnz_df.loc[alphas_nnz_df['Nb non-zero coefs'] == 8 ]\n",
    "higher_alpha_to_get_8_features = alphas_to_get_8_features.max()[0]\n",
    "index_higher_alpha_to_get_8_features = list(alpha_for_path).index(higher_alpha_to_get_8_features)\n",
    "#index_higher_alpha_to_get_8_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volume_nvi',\n",
       " 'volatility_bbhi',\n",
       " 'volatility_dcl',\n",
       " 'trend_adx',\n",
       " 'trend_cci',\n",
       " 'trend_dpo',\n",
       " 'trend_kst_sig',\n",
       " 'momentum_ppo_hist']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 8 selected features coressponding \n",
    "\n",
    "coefs_at_higher_alpha_to_get_8_features = coefs_lasso[0][:,index_higher_alpha_to_get_8_features]\n",
    "index_coefs_at_higher_alpha_to_get_8_features = coefs_at_higher_alpha_to_get_8_features.nonzero()[0]\n",
    "coefs_lasso[0][:,[index_higher_alpha_to_get_8_features,2]]\n",
    "selected_features = [indicators[i] for i in index_coefs_at_higher_alpha_to_get_8_features]\n",
    "selected_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
